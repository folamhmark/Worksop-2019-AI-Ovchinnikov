{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson1 — homework-Ovchinnikov.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/folamhmark/Worksop-2019-AI-Ovchinnikov/blob/master/Lesson1_%E2%80%94_homework_Ovchinnikov.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcCnSUr0IU9h",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning\n",
        "\n",
        "Начнём наш курс с исторической справки, когда и как что появилось:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1c-NlY2gB_yHj_jOzj0MmqizzFSsjZboI\" style=\"width:1066px;height:501px;\">\n",
        "\n",
        "Предполагается, что модель нейрона, используемая в искусственных нейросетях, называемая [перцептроном](https://ru.wikipedia.org/wiki/%D0%9F%D0%B5%D1%80%D1%86%D0%B5%D0%BF%D1%82%D1%80%D0%BE%D0%BD), соответствует биологическим нейронам головного мозга (предполоджение выдвинуто в 1957 году нейрофизиологом Фрэнком Розенблаттом).\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1wh2tZL8Z5H802sZ6j1rCJvqNI9PZjPwT\" style=\"width:533px;height:250px;\">\n",
        "\n",
        "На рисунке выше изображена одна из первых моделей нейросети (1965 год), однако веса в такой модели не подбирались в процессе обучения, а задавались исходя из каких-то базовых предположений.\n",
        "\n",
        "Помимо событий, отмеченных в таймлайне, нелишним будет упомянуть теорему об универсальной аппроксимации (1989 by George Cybenko), являющейся математическим доказательством того, что искусственная нейросеть способна аппроксимировать любую \"достаточно хорошую\" функцию:\n",
        "\n",
        "[Универсальная теорема об аппроксимации (википедии);](https://en.wikipedia.org/wiki/Universal_approximation_theorem)\n",
        "\n",
        "[Универсальная теорема об аппроксимации (оригинальная статья);](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.441.7873&rep=rep1&type=pdf)\n",
        "\n",
        "Начало 2000-ых называется также периодом AI Winter (вторая зима ИИ), поскольку все идеи уже были изложены, но по причине отсутствия больших наборов данных и производительных процессоров обучать сложные и глубокие нейросети не представлялось возможным...\n",
        "\n",
        "2012 год считается прорывным, поскольку тогда нейросеть [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), обученная на GPU, сумела выиграть соревнование по распознаванию изображений с большим отрывом (порядка 12%). Именно тогда поднялся хайп вокруг DL :)\n",
        "\n",
        "Еще одним прорывом было поражение [Ли Седоля в игру Go](https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol) весной 2016 года. AlphaGo был разработан лабораторией Google DeepMind во главе с Демисом Хасабисом. Игра Go считалась прежде непостижимой для AI по причине того, что количество возможных комбинаций ходов не позволяло аналитически строить дерево решений."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjFdUqCVIU9k",
        "colab_type": "text"
      },
      "source": [
        "## Логистическая регрессия"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cde48YI-IU9n",
        "colab_type": "text"
      },
      "source": [
        "В данном упражнении мы построим простейший классификатор изображений, основанный на логистической регрессии. \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=14TpTs8-VqVOFR9qMUW4mjMdC6sOpd5Bl\" style=\"width:618px;height:306px;\">\n",
        "\n",
        "Данные в модель мы будем подавать хитрым образом: изображение, то есть матрицу размером $(n,n)$ мы преобразуем в вектор столбец размерности $(n^2,1)$. После этого полученный многомерный вектор будем подавать на вход в модель. Такая модель предполагает, что $n$ необходимо определить заранее, перед обучением, и в дальнейшем его нельзя будет изменить (потребуется обучать модель заново). \n",
        "\n",
        "Таким образом, надо проверять, являются ли размеры изображения допустимыми перед тем, как подавать его в модель. Если нет, то можно воспользоваться функцией resize из библиотеки openCV, которая изменяет размеры изображения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "win6YkQiIU9o",
        "colab_type": "text"
      },
      "source": [
        "### Шаг 1. Инициализация модели\n",
        "\n",
        "Данная функция возвращает маccив $w$ и число $b$, которые на каждой итерации обучения будут обновляться."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLJ-qMzCIU9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_model(input_size=256):\n",
        "    \n",
        "    ###ЗАДАЧА: проинициализируйте веса модели так, чтобы массив w имел размер (input_size^2,1), а b был числом\n",
        "    w = np.ones((input_size ** 2, 1))\n",
        "    b = 1\n",
        "    return w, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DVJqj_TIU9w",
        "colab_type": "text"
      },
      "source": [
        "В нашей модели логистической регрессии по большому счету неважно, как были проинициализированы веса (можно проинициализировать все значения нулями, можно - случайными значениями, можно двойками и т.д.:) ). Однако для глубоких нейросетей это имеет очень большое значение, и $\\textbf{крайне не рекомендуется инициализировать значения нулями!}$ Об этом мы ещё обязательно поговорим в дальнейшем."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92Yo_7ryIU9x",
        "colab_type": "text"
      },
      "source": [
        "### Шаг 2. Обучение модели\n",
        "\n",
        "После того как мы задали начальные параметры (он пока был всего один - это размер  $n$) и проинициализировали веса, можно приступать к обучению модели.\n",
        "\n",
        "Обучение модели осуществляется в цикле и состоит из трех шагов:\n",
        "    - подсчет текущего значения функции ошибки\n",
        "    - подсчет градиента функции ошибки\n",
        "    - обновление весов модели\n",
        "    \n",
        "Вспомним теорию...\n",
        "\n",
        "Для i-ого образца $x^{(i)}$:\n",
        "\n",
        "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n",
        "\n",
        "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$$ \n",
        "\n",
        "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$$\n",
        "\n",
        "Подсчет функции ошибки - это суммирование потерь на всех образцах:\n",
        "\n",
        "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{4}$$\n",
        "\n",
        "**Задачи**:\n",
        "\n",
        "Необходимо будет реализовать следующие шаги: \n",
        "    - Инициализировать параметры модели\n",
        "    - Обучить параметры, минимизируя функцию потерь  \n",
        "    - Проверить модель на тестовом наборе данных\n",
        "    - Проанализировать обученную модель\n",
        "    \n",
        "Для начала необходимо будет объявить несколько вспомогательных функций, а затем собрать из них модель и начать обучение."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adVpUSMqIU9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(z):\n",
        "    ###ВАЖНО: функция принимает на вход массив любых размеров, на выход возвращает массив такого же размера\n",
        "    s = 1/(1+np.exp(-z))\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_gv0mwVIU91",
        "colab_type": "text"
      },
      "source": [
        "Еще раз выпишем формулы для вывода текущего предсказания, для текущей ошибки и для текущего градиента функции ошибки:\n",
        "\n",
        "    - Подсчитываем предсказание (forward propagation):\n",
        "    \n",
        "$$A = \\sigma(w^T X + b) = (a^{(1)}, a^{(2)}, ..., a^{(m-1)}, a^{(m)})\\tag{6}$$\n",
        "    - Подсчитываем функцию ошибки: \n",
        "    \n",
        "$$J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})\\tag{7}$$\n",
        "    - Подсчитываем градиент функции ошибки (backward propagation):\n",
        "    \n",
        "$$ \\frac{\\partial J}{\\partial w}=\\nabla J_w = \\frac{1}{m}X(A-Y)^T\\tag{8}$$\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial b} =\\frac{dJ}{db}= \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{9}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbuqfkeJIU92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def propagate(w, b, X, Y):\n",
        "    \"\"\"\n",
        "    Подсчет текущего предсказания (оно же forward propagation) и градиента функции ошибки (оно же backward propagation)\n",
        "\n",
        "    Input:\n",
        "    w -- веса, numpy_array размера (num_px * num_px * 3, 1)\n",
        "    b -- смещение, скалярная величина\n",
        "    X -- данные размера (num_px * num_px * 3, кол-во образцов)\n",
        "    Y -- вектор истинных ответов размера (1, кол-во образцов)\n",
        "\n",
        "    Return:\n",
        "    cost -- текущая функция потерь\n",
        "    dw -- градиент функции ошибки по w\n",
        "    db -- градиент функции ошибки по b (по сути производная по b)\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]\n",
        "    \n",
        "    A = s * (np.dot(w.T, X) + b)\n",
        "    cost = - (1 / m) * np.sum(np.multiply(Y, np.log(A)) + np.multiply(1 - y, np.log(1 - A)))\n",
        "    \n",
        "    \n",
        "    dw = 1/m * np.dot(X,(A - Y).T) \n",
        "    db = 1/m * np.sum(A - Y)\n",
        "    \n",
        "    \n",
        "    grads = {\"dw\": dw,\n",
        "             \"db\": db}\n",
        "    \n",
        "    return grads, cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCMy1lCabAZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmtMpf3AIU95",
        "colab_type": "text"
      },
      "source": [
        "Мы реализовали блоки для работы модели и для подсчета функции ошибки и необходимых градиентов. Теперь осталось реализовать функцию, осуществляющую обучение. \n",
        "\n",
        "**Под обучением мы сейчас и впредь будем иметь в виду обновление весов таким образом, чтобы функция ошибки на  обучающей выборке достигала минимума.**\n",
        "\n",
        "**Важно!!!** Под записями $dw$ и $db$ мы будем подразумевать соответствующие градиенты функции потерь, то есть $\\frac{\\partial J}{\\partial w}$(вектор) и $\\frac{\\partial J}{\\partial b} (скаляр)$.\n",
        "\n",
        " **Задание:** Реализуйте шаг обновления весов модели. Для параметра $w$ обновление выглядит так: \n",
        " \n",
        " $ w := w - \\alpha \\text{ } dw \\tag{10},$ а \n",
        " \n",
        " $$ b : = b - \\alpha \\text{ } db \\tag{11},$$\n",
        " \n",
        "где $\\alpha$ - некий коэффициент (который называется $\\textit{learning rate}$ - не будем переводить это на русский язык)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpXPeWNqIU97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
        "    \"\"\"\n",
        "    Оптимизация с помощью простого градиентного спуска\n",
        "    \n",
        "    Input:\n",
        "    w -- веса, numpy_array размера (num_px * num_px * 3, 1)\n",
        "    b -- смещение, скалярная величина\n",
        "    X -- данные размера (num_px * num_px * 3, кол-во образцов)\n",
        "    Y -- вектор истинных ответов размера (1, кол-во образцов)\n",
        "    num_iterations -- кол-во итераций алгоритма оптимизации\n",
        "    learning_rate -- коэффициент learning rate\n",
        "    print_cost -- True, если хотите выводить функцию ошибки на каждых 100 итерациях\n",
        "    \n",
        "    Returns:\n",
        "    params -- словарь, содержащий w и b\n",
        "    grads -- словарь, содержащий градиенты функции ошибки по w и b соответственно\n",
        "    costs -- массив (list) со значением функции ошибки для каждой итерации (так делают для визуализации)\n",
        "    \n",
        "    Подсказка:\n",
        "    \n",
        "        1) Используйте ранее написанную функцию propagate().\n",
        "        2) Обновляйте параметры w и b согласно формуле 10.\n",
        "    \"\"\"\n",
        "    \n",
        "    costs = []\n",
        "    \n",
        "    for i in range(num_iterations):\n",
        "        \n",
        "        \n",
        "        ###Напишите значения для градиентов и функции ошибки\n",
        "        grads, cost = propagate(w, b, X, Y)\n",
        "        \n",
        "        \n",
        "        # Retrieve derivatives from grads\n",
        "        dw = grads[\"dw\"]\n",
        "        db = grads[\"db\"]\n",
        "        \n",
        "        # обновление параметров\n",
        "        \n",
        "        ### START CODE HERE ###\n",
        "        w = w - learning_rate * dw\n",
        "        b = b - learning_rate * db\n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "        # Record the costs\n",
        "        if i % 100 == 0:\n",
        "            costs.append(cost)\n",
        "        \n",
        "        # Print the cost every 100 training iterations\n",
        "        if print_cost and i % 100 == 0:\n",
        "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
        "    \n",
        "    params = {\"w\": w,\n",
        "              \"b\": b}\n",
        "    \n",
        "    grads = {\"dw\": dw,\n",
        "             \"db\": db}\n",
        "    \n",
        "    return params, grads, costs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5_Ajej6IU-C",
        "colab_type": "text"
      },
      "source": [
        "Теперь реализуем функцию predict(), которая будет вызываться уже после обучения для предсказания моделью:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ssGA9HTIU-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(w, b, X):\n",
        "    '''\n",
        "    \n",
        "    Inputs:\n",
        "    w\n",
        "    b\n",
        "    X -- данные размера (num_px * num_px * 3, кол-во образцов)\n",
        "    \n",
        "    Returns:\n",
        "    Y_prediction\n",
        "    '''\n",
        "    \n",
        "    m = X.shape[1]\n",
        "    Y_prediction = np.zeros((1,m))\n",
        "    w = w.reshape(X.shape[0], 1)\n",
        "    \n",
        "    \n",
        "    ### START CODE HERE ### (≈ 1 line of code)\n",
        "    A = sigmoid(np.dot(w.T,X)+b)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    for i in range(A.shape[1]):\n",
        "        \n",
        "        # Установите порог, выше которого считаем, что модель выдает 1, а ниже - ноль\n",
        "        ### START CODE HERE ###\n",
        "        if (A[0,i] <= 0.5):\n",
        "            Y_prediction[0,i] = 0\n",
        "        else:\n",
        "            Y_prediction[0,i] = 1\n",
        "        ### END CODE HERE ###\n",
        "    \n",
        "    \n",
        "    return Y_prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fyB4AQ9IU-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttuTeWs5Dvji",
        "colab_type": "text"
      },
      "source": [
        "### Необходимые библиотеки\n",
        "\n",
        "Перед запуском программ необходимо импортировать следующие библиотеки:\n",
        "\n",
        "```python\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3k7ppmHfMf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5UgJ5XtQz1i",
        "colab_type": "text"
      },
      "source": [
        "**Важно:**\n",
        "Как монтировать google drive?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0LQZTllQy6P",
        "colab_type": "code",
        "outputId": "825f36b5-377c-4ffb-b4b3-4e40da077339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "### path = 'gdrive/My\\ Drive/__путь_к_папке__'"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-319cc6c89a91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/MFTI Science/lesson1_dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m### path = 'gdrive/My\\ Drive/__путь_к_папке__'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmountpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not contain a space.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must not contain a space."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fmXutJUQzRq",
        "colab_type": "text"
      },
      "source": [
        "### Парсер данных\n",
        "\n",
        "Парсер файлов уже написан и приведен ниже. В качестве аргументов ему передаются X - пустое значение, Y - пустой NumPy массив, path - директория к изображением, ans - ответ (1 - если в этой директории лежат кадры с коробками, 0 - если наоборот)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou_l2zlIAbKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = None\n",
        "Y = np.array([])\n",
        "def read_files(X, Y, path, ans):\n",
        "  files = os.listdir(path)\n",
        "  for name in files:\n",
        "    img = cv2.imread(path + '/' + name, 0)\n",
        "    if img.shape != 0:\n",
        "      img = cv2.resize(img, (256, 256))\n",
        "      vect = img.reshape(1, 256 ** 2)\n",
        "      vect = vect / 255.\n",
        "      X = vect if (X is None) else np.vstack((X, vect)) \n",
        "      Y = np.append(Y, ans)\n",
        "  return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}